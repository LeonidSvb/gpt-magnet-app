---
description: Architectural Decision Records
globs:
alwaysApply: false
---

# Architecture Decision Log

<!--
ADR_AGENT_PROTOCOL v1.0

You (the agent) manage this file as the single source of truth for all ADRs.

INVARIANTS
- Keep this exact file structure and headings.
- All ADR entries use H2 headings: "## ADR-XXXX — <Title>" (4-digit zero-padded ID).
- Allowed Status values: Proposed | Accepted | Superseded
- Date format: YYYY-MM-DD
- New entries must be appended to the END of the file.
- The Index table between the INDEX markers must always reflect the latest state and be sorted by ID desc (newest on top).
- Each ADR MUST contain: Date, Status, Owner, Context, Decision, Consequences.
- Each ADR must include an explicit anchor `<a id="adr-XXXX"></a>` so links remain stable.

HOW TO ADD A NEW ADR
1) Read the whole file.
2) Compute next ID:
   - Scan for headings matching: ^## ADR-(\\d{4}) — .+$
   - next_id = (max captured number) + 1, left-pad to 4 digits.
3) Create a new ADR section using the "New ADR Entry Template" below.
   - Place it AFTER the last ADR section in the file.
   - Add an `<a id="adr-XXXX"></a>` line immediately below the heading.
4) Update the Index (between the INDEX markers):
   - Insert/replace the row for this ADR keeping the table sorted by ID descending.
   - Title in the Index MUST link to the anchor: [<Title>](#adr-XXXX)
   - If this ADR supersedes another: set "Supersedes" in this row, and update that older ADR:
       a) Change its Status to "Superseded"
       b) Add "Superseded by: ADR-XXXX" in its Consequences block
       c) Update the older ADR's Index row "Superseded by" column to ADR-XXXX
5) Validate before saving:
   - Exactly one heading exists for ADR-XXXX
   - All required fields are present and non-empty
   - Index contains a row for ADR-XXXX and remains properly sorted
6) Concurrency resolution:
   - If a merge conflict or duplicate ID is detected after reading: recompute next_id from the current file state, rename your heading, anchor, and Index row accordingly, and retry once.

COMMIT MESSAGE SUGGESTION
- "ADR-XXXX: <Short Title> — <Status>"

END ADR_AGENT_PROTOCOL
-->

## Index

<!-- BEGIN:ADR_INDEX -->

| ID   | Title                                                        | Date       | Status   | Supersedes | Superseded by |
| ---- | ------------------------------------------------------------ | ---------- | -------- | ---------- | ------------- |
| 0008 | [Test Infrastructure Integration](#adr-0008)                 | 2025-09-28 | Accepted | —          | —             |
| 0007 | [Feature Flag Architecture for Business Types](#adr-0007)   | 2025-09-28 | Accepted | —          | —             |
| 0006 | [Alfie Design System Import](#adr-0006)                     | 2025-09-28 | Accepted | —          | —             |
| 0005 | [MVP Question Architecture Rewrite](#adr-0005)              | 2025-09-28 | Accepted | —          | —             |
| 0004 | [PostHog + Supabase Dual Analytics Architecture](#adr-0004) | 2025-01-20 | Accepted | —          | —             |
| 0003 | [Supabase Three-Table Architecture (Sessions, Leads, Results)](#adr-0003) | 2025-01-20 | Accepted | —          | —             |
| 0002 | [OpenAI GPT-4o-mini for AI Result Generation](#adr-0002)    | 2025-01-20 | Accepted | —          | —             |
| 0001 | [Next.js 14 + Supabase + Vercel Stack](#adr-0001)           | 2025-01-20 | Accepted | —          | —             |

<!-- END:ADR_INDEX -->

---

## New ADR Entry Template (copy for each new decision)

> Replace placeholders, keep section headers. Keep prose concise.

```

## ADR-XXXX — \<Short, specific title>

<a id="adr-XXXX"></a>
**Date**: YYYY-MM-DD
**Status**: Proposed | Accepted | Superseded
**Owner**: <Name>

### Context

<1–3 sentences: what changed or what forces drive this decision now>

### Alternatives

<Quick bullet list of alternatives considered, and why they were rejected.>

### Decision

\<Single clear decision in active voice; make it testable/verifiable>

### Consequences

* **Pros**: \<benefit 1>, \<benefit 2>
* **Cons / risks**: \<cost 1>, \<risk 1>
* **Supersedes**: ADR-NNNN (if any)
* **Superseded by**: ADR-MMMM (filled later if replaced)

### (Optional) Compliance / Verification

\<How we'll check this is honored: tests, checks, fitness functions, runbooks>

```

---

## ADR-0001 — Next.js 14 + Supabase + Vercel Stack

<a id="adr-0001"></a>
**Date**: 2025-01-20
**Status**: Accepted
**Owner**: Development Team

### Context

GPT Lead Magnet requires a scalable, serverless architecture that handles AI generation, database operations, and analytics. The system must support both web and Telegram platforms with minimal infrastructure overhead.

### Alternatives

- **Next.js + Vercel Postgres**: Simpler but lacks built-in auth and storage features
- **Pure React SPA + Backend API**: More flexible but requires separate infrastructure
- **Supabase only (no Next.js)**: Database-centric but lacks frontend optimization
- **Next.js 14 + Supabase + Vercel**: Best of both worlds - serverless frontend + powerful backend

### Decision

Use Next.js 14 (App Router) deployed on Vercel with Supabase as backend. This provides:
- Serverless API routes for OpenAI integration
- Supabase PostgreSQL for sessions, leads, results storage
- Built-in TypeScript support and type safety
- Easy deployment and scalability on Vercel
- Future-ready for Supabase Auth and Storage if needed

### Consequences

- **Pros**: Serverless architecture scales automatically, Supabase free tier generous (500MB DB + 2GB bandwidth), excellent DX with TypeScript, zero infrastructure management, Vercel edge network for fast global delivery
- **Cons / risks**: Vendor lock-in to Vercel + Supabase, cold start latency for API routes, need to monitor Supabase usage limits
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- Next.js 14 successfully deployed on Vercel
- Supabase client connects without errors
- API routes respond in <2 seconds (warm)
- Environment variables properly configured

---

## ADR-0002 — OpenAI GPT-4o-mini for AI Result Generation

<a id="adr-0002"></a>
**Date**: 2025-01-20
**Status**: Accepted
**Owner**: Development Team

### Context

The core value of GPT Lead Magnet is generating personalized AI results based on user questionnaire answers. The AI model must balance cost, quality, and response time.

### Alternatives

- **GPT-4**: Highest quality but expensive ($0.03/1K tokens) and slower
- **GPT-4o-mini**: Good balance of quality/cost ($0.00015/1K tokens), fast
- **GPT-3.5-turbo**: Cheapest but lower quality output
- **Claude/Gemini**: Alternative providers but adds complexity

### Decision

Use OpenAI GPT-4o-mini as the default model for AI result generation:
- Fast response times (2-5 seconds typical)
- Cost-effective at $0.00015/1K input tokens
- Sufficient quality for lead magnet content
- Markdown output support for rich formatting
- Easy to upgrade to GPT-4 for premium clients later

### Consequences

- **Pros**: 20x cheaper than GPT-4, fast generation (<5s), good enough quality for MVP, scalable to thousands of requests, markdown formatting built-in
- **Cons / risks**: OpenAI API dependency, rate limits need monitoring, occasional lower quality vs GPT-4, need fallback handling for API errors
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- Average generation time <5 seconds
- Token usage tracked in `results` table
- Cost per generation <$0.01
- Markdown output renders properly in React

---

## ADR-0003 — Supabase Three-Table Architecture (Sessions, Leads, Results)

<a id="adr-0003"></a>
**Date**: 2025-01-20
**Status**: Accepted
**Owner**: Development Team

### Context

Database architecture must support the full lead magnet flow: questionnaire → AI generation → lead capture → CRM integration. Data must be structured for analytics while remaining flexible for schema changes.

### Alternatives

- **Single monolithic table**: Simple but inflexible and poor for analytics
- **Sessions + Leads only**: Loses AI generation metadata and costs tracking
- **Separate DB per entity**: Over-engineered for MVP
- **Three tables (Sessions, Leads, Results)**: Clean separation of concerns with proper foreign keys

### Decision

Implement three-table Supabase architecture:

**1. `sessions`** - Every quiz completion
- UUID primary key
- `answers` (JSONB) - flexible questionnaire data
- `status` (started/completed/abandoned)
- `source` (web/telegram/iframe)
- `current_step`, `total_steps` - progress tracking
- Metadata: user_agent, ip_address, timestamps

**2. `leads`** - Contact information
- UUID primary key, foreign key to `sessions`
- `email` OR `telegram_id` (constraint enforces one required)
- `name`, `phone`, `company` - optional fields
- `status` (new/contacted/converted) - sales pipeline

**3. `results`** - AI-generated content
- UUID primary key, foreign key to `sessions`
- `markdown` - AI output
- `prompt_used` - audit trail
- `model`, `tokens_used`, `generation_time_ms` - cost tracking
- `version` - for A/B testing prompts

### Consequences

- **Pros**: Clean data separation, flexible JSONB for answers, proper foreign keys prevent orphans, easy to add fields without migrations, tracks AI costs per session, supports both web + Telegram, ready for analytics queries
- **Cons / risks**: Three joins needed for full session data, JSONB queries less performant than structured columns, need to maintain TypeScript types in sync
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- [x] All tables created with proper constraints
- [x] Foreign keys enforce referential integrity
- [x] Indexes added on email, telegram_id, session_id
- [x] TypeScript types generated in `types/database.ts`
- [x] `lib/supabase-queries.ts` provides type-safe CRUD functions

---

## ADR-0004 — PostHog + Supabase Dual Analytics Architecture

<a id="adr-0004"></a>
**Date**: 2025-01-20
**Status**: Accepted
**Owner**: Development Team

### Context

Need analytics for both product behavior (funnels, A/B tests) and business data (lead quality, AI costs). Single solution either loses behavioral insights or bloats database with event logs.

### Alternatives

- **Supabase only**: Store all events in DB but expensive and poor funnel visualization
- **PostHog only**: Great for events but can't store full user answers and AI results
- **Google Analytics**: Free but limited product analytics features
- **PostHog + Supabase**: Best of both - events in PostHog, business data in Supabase

### Decision

Use dual analytics architecture where each tool handles its strength:

**PostHog** - Product analytics (behavior):
- Events: `wizard_started`, `question_answered`, `wizard_abandoned`, `result_generated`, `lead_submitted`
- Properties: step number, time spent, variant (for A/B tests)
- Funnel analysis and drop-off visualization
- Feature flags for A/B testing

**Supabase** - Business data (what users said):
- Full questionnaire answers in `sessions.answers` (JSONB)
- Lead contact info for CRM integration
- AI results for re-delivery to users
- Cost tracking (tokens, generation time)

**No duplication**: Never store full answers in PostHog, never store click events in Supabase.

### Consequences

- **Pros**: PostHog shows WHERE users drop off, Supabase shows WHAT they answered when they stayed, clean separation prevents data duplication, PostHog free tier (1M events/month), easy to add materialized views in Supabase for aggregate stats, A/B testing ready with feature flags
- **Cons / risks**: Two systems to maintain, need to correlate session_id across both, PostHog adds ~50KB to bundle size, need to handle PostHog being blocked by ad blockers
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- PostHog initialized in `lib/analytics.ts`
- Events tracked at key funnel steps
- Supabase stores only business-critical data
- No duplication of user answers in PostHog
- Session IDs used to correlate data across systems

---

## ADR-0005 — MVP Question Architecture Rewrite

<a id="adr-0005"></a>
**Date**: 2025-09-28
**Status**: Accepted
**Owner**: Development Team

### Context

Original questions focused on assessing the coach themselves rather than understanding their clients. For effective lead magnet generation, we need questions about the coach's CLIENT demographics, pain points, and desired transformations. This is a meta-level product where coaches get value immediately and then want implementation services.

### Alternatives

- **Keep generic assessment approach**: Simple but doesn't generate personalized lead magnets
- **Mix coach + client questions**: Confusing and unfocused
- **Pure client-focused questions**: Clear purpose but requires complete rewrite
- **External questionnaire service**: Adds dependency and reduces control

### Decision

Completely rewrite questions.ts to focus on coach's CLIENTS rather than coaches:
- 10 optimized questions for lead magnet generation
- Target: client demographics, pain points, transformations, unique methods
- Smart field sizing (small/medium/large) based on expected answer length
- Built-in hints and help text for better answer quality
- Modular business type structure: Soft Coach, Hard Coach, Agency, Other Professional

### Consequences

- **Pros**: Lead magnets actually personalized to coach's niche, meta-product demonstrates value immediately, clear qualification questions for segmentation, smart UX reduces friction
- **Cons / risks**: Complete rewrite requires extensive testing, potential bugs in new question logic, need to validate with real coaches, current system completely replaced
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- All 10 questions focus on client characteristics, not coach assessment
- Smart hints guide users to better answers
- Field sizes optimize for expected content length
- Business type selector works with feature flag system

---

## ADR-0006 — Alfie Design System Import

<a id="adr-0006"></a>
**Date**: 2025-09-28
**Status**: Accepted
**Owner**: Development Team

### Context

Need battle-tested UI components to avoid "bumps" already solved in outdoor project. Current basic components lack proper validation, user guidance, and responsive design. Outdoor project has proven QuestionCard and ProgressBar components with iframe compatibility.

### Alternatives

- **Build from scratch**: Full control but repeat solved problems
- **Use generic UI library**: Consistent but not optimized for questionnaires
- **Import specific components from outdoor**: Proven solutions, fast implementation
- **Copy-paste and modify**: Risk of introducing bugs from incomplete copying

### Decision

Import and adapt Alfie design system components from outdoor project:
- **QuestionCard.tsx**: Auto-advance for single choice, proper validation, all field types
- **ProgressBar.tsx**: Emoji milestones, animated progress dots, celebration effects
- **Complete CSS system**: Alfie color palette, component styles, iframe compatibility
- **Smart interaction patterns**: Back/next navigation, loading states, error handling

### Consequences

- **Pros**: Proven components with edge cases handled, consistent Alfie branding, iframe compatibility tested, responsive design included, saves weeks of development
- **Cons / risks**: Dependency on outdoor project patterns, need to maintain consistency across projects, some over-engineering for simple use cases
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- QuestionCard supports all question types (text, single-choice, multiple-choice, multi-with-other)
- ProgressBar shows proper milestone progression
- CSS variables work consistently across components
- Iframe embedding works without style conflicts

---

## ADR-0007 — Feature Flag Architecture for Business Types

<a id="adr-0007"></a>
**Date**: 2025-09-28
**Status**: Accepted
**Owner**: Development Team

### Context

Need to launch MVP with single business type (Soft Coach) for validation, then gradually activate additional types. Hard-coding business types would require code changes for each activation. Feature flag system allows controlled rollout without deployments.

### Alternatives

- **All business types active**: Risk of untested flows going live
- **Hard-coded single type**: Requires code changes for expansion
- **External feature flag service**: Adds complexity and dependency
- **Simple boolean flags per type**: Built-in control, easy to expand

### Decision

Implement business type feature flags using getActiveBusinessTypes() function:
- **Soft Coach**: ACTIVE - Personal coaches working with individuals
- **Hard Coach**: DISABLED - Business coaches working with entrepreneurs
- **Agency**: DISABLED - Marketing agencies and teams
- **Other Professional**: DISABLED - Consultants, therapists, other professionals

Each type has complete question set prepared but activation controlled by feature flags.

### Consequences

- **Pros**: Safe MVP launch with single validated flow, easy activation without code deployment, prepared for all business types, clean abstraction for future types
- **Cons / risks**: Unused code in production, need to maintain all question sets even if not active, potential confusion between different business type flows
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- getActiveBusinessTypes() returns only enabled business types
- BusinessTypeSelector shows only active options
- All question sets remain in code but only active ones accessible
- Feature flags easily toggled in single location

---

## ADR-0008 — Test Infrastructure Integration

<a id="adr-0008"></a>
**Date**: 2025-09-28
**Status**: Accepted
**Owner**: Development Team

### Context

Complete rewrite of question system requires comprehensive manual testing. Need easy way to test all business types, question flows, validation, and final output without going through full production flow. Must verify analytics tracking and component interactions.

### Alternatives

- **Production testing only**: Risks breaking live system
- **Separate test environment**: Complex setup and maintenance
- **Built-in test page**: Easy access, controlled environment
- **Unit tests only**: Misses integration and user experience issues

### Decision

Implement comprehensive test infrastructure with /test-questions route:
- **TestQuestionsPage**: Full flow from business type selection to final answers
- **JSON output display**: Verify answer structure and validation
- **Analytics tracking**: All PostHog events fired in test mode
- **Reset functionality**: Easy to test multiple scenarios
- **Console logging**: Debug answer processing and validation

### Consequences

- **Pros**: Easy manual testing of complete flows, JSON output validates data structure, analytics events testable, quick iteration on UX issues, accessible to non-technical team members
- **Cons / risks**: Test code in production bundle (minimal impact), manual testing still required, need to remember to test after changes, potential for test-production differences
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- /test-questions route accessible and functional
- All business types testable (active and inactive)
- JSON output matches expected answer structure
- Analytics events fire correctly in test mode
- Reset button works properly for repeated testing

---