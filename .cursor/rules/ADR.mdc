---
description: Architectural Decision Records
globs:
alwaysApply: false
---

# Architecture Decision Log

<!--
ADR_AGENT_PROTOCOL v1.0

You (the agent) manage this file as the single source of truth for all ADRs.

INVARIANTS
- Keep this exact file structure and headings.
- All ADR entries use H2 headings: "## ADR-XXXX — <Title>" (4-digit zero-padded ID).
- Allowed Status values: Proposed | Accepted | Superseded
- Date format: YYYY-MM-DD
- New entries must be appended to the END of the file.
- The Index table between the INDEX markers must always reflect the latest state and be sorted by ID desc (newest on top).
- Each ADR MUST contain: Date, Status, Owner, Context, Decision, Consequences.
- Each ADR must include an explicit anchor `<a id="adr-XXXX"></a>` so links remain stable.

HOW TO ADD A NEW ADR
1) Read the whole file.
2) Compute next ID:
   - Scan for headings matching: ^## ADR-(\\d{4}) — .+$
   - next_id = (max captured number) + 1, left-pad to 4 digits.
3) Create a new ADR section using the "New ADR Entry Template" below.
   - Place it AFTER the last ADR section in the file.
   - Add an `<a id="adr-XXXX"></a>` line immediately below the heading.
4) Update the Index (between the INDEX markers):
   - Insert/replace the row for this ADR keeping the table sorted by ID descending.
   - Title in the Index MUST link to the anchor: [<Title>](#adr-XXXX)
   - If this ADR supersedes another: set "Supersedes" in this row, and update that older ADR:
       a) Change its Status to "Superseded"
       b) Add "Superseded by: ADR-XXXX" in its Consequences block
       c) Update the older ADR's Index row "Superseded by" column to ADR-XXXX
5) Validate before saving:
   - Exactly one heading exists for ADR-XXXX
   - All required fields are present and non-empty
   - Index contains a row for ADR-XXXX and remains properly sorted
6) Concurrency resolution:
   - If a merge conflict or duplicate ID is detected after reading: recompute next_id from the current file state, rename your heading, anchor, and Index row accordingly, and retry once.

COMMIT MESSAGE SUGGESTION
- "ADR-XXXX: <Short Title> — <Status>"

END ADR_AGENT_PROTOCOL
-->

## Index

<!-- BEGIN:ADR_INDEX -->

| ID   | Title                                                        | Date       | Status   | Supersedes | Superseded by |
| ---- | ------------------------------------------------------------ | ---------- | -------- | ---------- | ------------- |
| 0004 | [PostHog + Supabase Dual Analytics Architecture](#adr-0004) | 2025-01-20 | Accepted | —          | —             |
| 0003 | [Supabase Three-Table Architecture (Sessions, Leads, Results)](#adr-0003) | 2025-01-20 | Accepted | —          | —             |
| 0002 | [OpenAI GPT-4o-mini for AI Result Generation](#adr-0002)    | 2025-01-20 | Accepted | —          | —             |
| 0001 | [Next.js 14 + Supabase + Vercel Stack](#adr-0001)           | 2025-01-20 | Accepted | —          | —             |

<!-- END:ADR_INDEX -->

---

## New ADR Entry Template (copy for each new decision)

> Replace placeholders, keep section headers. Keep prose concise.

```

## ADR-XXXX — \<Short, specific title>

<a id="adr-XXXX"></a>
**Date**: YYYY-MM-DD
**Status**: Proposed | Accepted | Superseded
**Owner**: <Name>

### Context

<1–3 sentences: what changed or what forces drive this decision now>

### Alternatives

<Quick bullet list of alternatives considered, and why they were rejected.>

### Decision

\<Single clear decision in active voice; make it testable/verifiable>

### Consequences

* **Pros**: \<benefit 1>, \<benefit 2>
* **Cons / risks**: \<cost 1>, \<risk 1>
* **Supersedes**: ADR-NNNN (if any)
* **Superseded by**: ADR-MMMM (filled later if replaced)

### (Optional) Compliance / Verification

\<How we'll check this is honored: tests, checks, fitness functions, runbooks>

```

---

## ADR-0001 — Next.js 14 + Supabase + Vercel Stack

<a id="adr-0001"></a>
**Date**: 2025-01-20
**Status**: Accepted
**Owner**: Development Team

### Context

GPT Lead Magnet requires a scalable, serverless architecture that handles AI generation, database operations, and analytics. The system must support both web and Telegram platforms with minimal infrastructure overhead.

### Alternatives

- **Next.js + Vercel Postgres**: Simpler but lacks built-in auth and storage features
- **Pure React SPA + Backend API**: More flexible but requires separate infrastructure
- **Supabase only (no Next.js)**: Database-centric but lacks frontend optimization
- **Next.js 14 + Supabase + Vercel**: Best of both worlds - serverless frontend + powerful backend

### Decision

Use Next.js 14 (App Router) deployed on Vercel with Supabase as backend. This provides:
- Serverless API routes for OpenAI integration
- Supabase PostgreSQL for sessions, leads, results storage
- Built-in TypeScript support and type safety
- Easy deployment and scalability on Vercel
- Future-ready for Supabase Auth and Storage if needed

### Consequences

- **Pros**: Serverless architecture scales automatically, Supabase free tier generous (500MB DB + 2GB bandwidth), excellent DX with TypeScript, zero infrastructure management, Vercel edge network for fast global delivery
- **Cons / risks**: Vendor lock-in to Vercel + Supabase, cold start latency for API routes, need to monitor Supabase usage limits
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- Next.js 14 successfully deployed on Vercel
- Supabase client connects without errors
- API routes respond in <2 seconds (warm)
- Environment variables properly configured

---

## ADR-0002 — OpenAI GPT-4o-mini for AI Result Generation

<a id="adr-0002"></a>
**Date**: 2025-01-20
**Status**: Accepted
**Owner**: Development Team

### Context

The core value of GPT Lead Magnet is generating personalized AI results based on user questionnaire answers. The AI model must balance cost, quality, and response time.

### Alternatives

- **GPT-4**: Highest quality but expensive ($0.03/1K tokens) and slower
- **GPT-4o-mini**: Good balance of quality/cost ($0.00015/1K tokens), fast
- **GPT-3.5-turbo**: Cheapest but lower quality output
- **Claude/Gemini**: Alternative providers but adds complexity

### Decision

Use OpenAI GPT-4o-mini as the default model for AI result generation:
- Fast response times (2-5 seconds typical)
- Cost-effective at $0.00015/1K input tokens
- Sufficient quality for lead magnet content
- Markdown output support for rich formatting
- Easy to upgrade to GPT-4 for premium clients later

### Consequences

- **Pros**: 20x cheaper than GPT-4, fast generation (<5s), good enough quality for MVP, scalable to thousands of requests, markdown formatting built-in
- **Cons / risks**: OpenAI API dependency, rate limits need monitoring, occasional lower quality vs GPT-4, need fallback handling for API errors
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- Average generation time <5 seconds
- Token usage tracked in `results` table
- Cost per generation <$0.01
- Markdown output renders properly in React

---

## ADR-0003 — Supabase Three-Table Architecture (Sessions, Leads, Results)

<a id="adr-0003"></a>
**Date**: 2025-01-20
**Status**: Accepted
**Owner**: Development Team

### Context

Database architecture must support the full lead magnet flow: questionnaire → AI generation → lead capture → CRM integration. Data must be structured for analytics while remaining flexible for schema changes.

### Alternatives

- **Single monolithic table**: Simple but inflexible and poor for analytics
- **Sessions + Leads only**: Loses AI generation metadata and costs tracking
- **Separate DB per entity**: Over-engineered for MVP
- **Three tables (Sessions, Leads, Results)**: Clean separation of concerns with proper foreign keys

### Decision

Implement three-table Supabase architecture:

**1. `sessions`** - Every quiz completion
- UUID primary key
- `answers` (JSONB) - flexible questionnaire data
- `status` (started/completed/abandoned)
- `source` (web/telegram/iframe)
- `current_step`, `total_steps` - progress tracking
- Metadata: user_agent, ip_address, timestamps

**2. `leads`** - Contact information
- UUID primary key, foreign key to `sessions`
- `email` OR `telegram_id` (constraint enforces one required)
- `name`, `phone`, `company` - optional fields
- `status` (new/contacted/converted) - sales pipeline

**3. `results`** - AI-generated content
- UUID primary key, foreign key to `sessions`
- `markdown` - AI output
- `prompt_used` - audit trail
- `model`, `tokens_used`, `generation_time_ms` - cost tracking
- `version` - for A/B testing prompts

### Consequences

- **Pros**: Clean data separation, flexible JSONB for answers, proper foreign keys prevent orphans, easy to add fields without migrations, tracks AI costs per session, supports both web + Telegram, ready for analytics queries
- **Cons / risks**: Three joins needed for full session data, JSONB queries less performant than structured columns, need to maintain TypeScript types in sync
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- [x] All tables created with proper constraints
- [x] Foreign keys enforce referential integrity
- [x] Indexes added on email, telegram_id, session_id
- [x] TypeScript types generated in `types/database.ts`
- [x] `lib/supabase-queries.ts` provides type-safe CRUD functions

---

## ADR-0004 — PostHog + Supabase Dual Analytics Architecture

<a id="adr-0004"></a>
**Date**: 2025-01-20
**Status**: Accepted
**Owner**: Development Team

### Context

Need analytics for both product behavior (funnels, A/B tests) and business data (lead quality, AI costs). Single solution either loses behavioral insights or bloats database with event logs.

### Alternatives

- **Supabase only**: Store all events in DB but expensive and poor funnel visualization
- **PostHog only**: Great for events but can't store full user answers and AI results
- **Google Analytics**: Free but limited product analytics features
- **PostHog + Supabase**: Best of both - events in PostHog, business data in Supabase

### Decision

Use dual analytics architecture where each tool handles its strength:

**PostHog** - Product analytics (behavior):
- Events: `wizard_started`, `question_answered`, `wizard_abandoned`, `result_generated`, `lead_submitted`
- Properties: step number, time spent, variant (for A/B tests)
- Funnel analysis and drop-off visualization
- Feature flags for A/B testing

**Supabase** - Business data (what users said):
- Full questionnaire answers in `sessions.answers` (JSONB)
- Lead contact info for CRM integration
- AI results for re-delivery to users
- Cost tracking (tokens, generation time)

**No duplication**: Never store full answers in PostHog, never store click events in Supabase.

### Consequences

- **Pros**: PostHog shows WHERE users drop off, Supabase shows WHAT they answered when they stayed, clean separation prevents data duplication, PostHog free tier (1M events/month), easy to add materialized views in Supabase for aggregate stats, A/B testing ready with feature flags
- **Cons / risks**: Two systems to maintain, need to correlate session_id across both, PostHog adds ~50KB to bundle size, need to handle PostHog being blocked by ad blockers
- **Supersedes**: —
- **Superseded by**: —

### Compliance / Verification

- PostHog initialized in `lib/analytics.ts`
- Events tracked at key funnel steps
- Supabase stores only business-critical data
- No duplication of user answers in PostHog
- Session IDs used to correlate data across systems

---